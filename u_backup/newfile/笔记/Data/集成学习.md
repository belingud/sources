# 贝叶斯方程：

$$P(A|B) = {{P(B|A)P(A)}\over{P(B)}}$$

条件多，可选样本集太大，不易于收集数据

朴素贝叶斯：不影响正负样本中，概率的大小比较，大大缩减了样本集中，样本的数量

主要解决：文本分类问题（NLTK，Word2vec）

三种模型：

1. 高斯分布朴素贝叶斯（处理数据据特征复合高斯分布的比较有效）
2. 多项式分布朴素贝叶斯（次品个数），处理大样本集的表现比较好（文章，小说，新闻）
3. 伯努利分布朴素贝叶斯（次品是否出现），处理小样本集的表现比较好（短信，邮件，简报）

**集成学习**

- Bagging：随机森林、极度随机森林，构建多个决策树，对不同的样本子集进行预测，最终投票预测结果
- Boosting：
    - 加法
        - Adaboost，调整每一个数的权重（预测的越准权重调的越小）
        - DBRT，梯度提升树，调整梯度变化，用残差构建新的树

机器学习分类：

- 有监督学习：
    - KNN
    - Logistic
    - LinearRegression
- 无监督学习：
    - KMeans：`from sklearn.cluster import KMeans`
- 半监督学习：


# K-means算法

1. 导包：`from skearn.cluster import KMeans`
2. 创建学习对象：`kmean = KMeans(n_clusters=2)`
3. 无监督学习
4. 预测
5. 获取聚类中心：`centers = kmean.cluster_centers_`
6. 绘制预测结果和聚类中心

完整代码：

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
%matplotlib inline

X, y = make_blobs(n_samples=100, n_features=2, centers=2, cluster_std=2, random_state=3)

kmean = KMeans(n_clusters=2)
kmean.fit(X)
y_ = kmean.predict(x)
# y_是一个dtype为int32的一维数组
# centers的长度就是make_blobs时定义的centers的个数
centers = kmean.clusters_centers_
plt.figure(figsize=(12, 5))
# 分隔画布为两块，一块绘制真实数据，一块绘制预测数据
ax1 = plt.subplot(121)
ax1.set_title('True')
ax1.scatter(X[:, 0], X[:, 1], c=y)

ax2 = plt.subplot(122)
ax2.set_title('Predict')
ax2.scatter(X[:, 0], X[:, 1], c=y_)
# 绘制聚类中心点
ax2.scatter(centers[:, 0], centers[:, 1], color='green', s=60)
```

当条件达到三个时，需要绘制3D图像来表现他们对数据的影响


# SVM

- linear：普通线型可分
- rbf：线型不可分
- poly：rbf收益不客观时使用，算法复杂度较高





